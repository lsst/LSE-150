\section{System Architecture} \label{sec:sysarc}


The LSST control system is based on a reactive data-driven actor-based architecture that uses a multi cast Data Distribution Service 
(DDS) messaging protocol middleware. A high level view of this architecture is given in \figref{fig:arc}, where each box corresponds to a 
component of the system (not all components are displayed here).

The LSST System Architecture is comprised mainly of;
%
\begin{itemize}
\item The Service Abstraction Layer (SAL\footnote{\url{https://docushare.lsstcorp.org/docushare/dsweb/Get/Document-21527/}}) communication middleware. Based on the DDS protocol, it provides interfaces for all the project adopted programming languages (LabView, C++, Java and Python).
\item Engineering and Facility Database (EFD).
\item SAL-aware reactive components, a.k.a Commandable SAL Components (CSCs).
\item LSST Operators Visualization Environment (LOVE).
\end{itemize}

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{arc}
\caption{High Level Architecture Diagram.\label{fig:arc}}
\end{center}
\end{figure}

The SAL middleware is the backbone of the LSST system architecture. It is a high level layer on top of Data 
Distribution Service (DDS), a standard message passing system. LSST uses the PrismTech OpenSplice DDS library, 
community edition. It implements three distinct types of messages; Commands, Events and Telemetry, with distinct 
purposes. Commands are sent to a specific component, which must acknowledge its receipt and perform some action. 
In general, the receiving component will be the only entity listening for the commands it accepts\footnote{But note that the EFD, for instance, will also be listening for 
commands, though it will not acknowledge them.}. Events and Telemetry are messages broadcast by components to the 
middleware and are available to any entity on the system to receive. The distinction between Events and Telemetry is that 
Events are output when conditions change, whereas Telemetry is output at semi-regular intervals. As such, it is much more 
important that Events be transmitted reliably than Telemetry. We cannot afford to lose any events, but we can lose occasional 
Telemetry. Thus Events are sent using a higher Quality of Service (QoS).

The EFD is responsible for capturing all SAL messages broadcasts to the middleware (including Commands, Events and Telemetry) and storing that information into a database.

CSCs are the main actors of the LSST system architecture. They are responsible for managing the incoming traffic of data and take 
appropriate actions, controlling hardware (e.g. M1M3, M2, Mount Controller, etc in Fig.~\ref{fig:arc}), software (e.g. Optics Controller 
Reconstructor, DMCS Interface, etc in Fig.~\ref{fig:arc}) or even other CSCs (e.g. ScriptQueue, TCS, ATCS, OCS, etc in 
Fig.~\ref{fig:arc} ).

LOVE is responsible for capturing SAL messages and displaying them in a useful way for general users, providing some basic interface to 
query and analyze data from the EFD, an interface to issue pre-defined commands to a set of components and user interaction with the 
ScriptQueue (see Sect.~\ref{sect:scriptq}).

The SAL processes XML based definitions of the Commands, Events, and Telemetry for each CSC. Using this information, it creates 
runtime objects which support the messaging required. These take the form of shared libraries (C++, Python, LabVIEW) or Jar archives 
(Java) which implement consistent namespaces and API's. Other assets such as Simulated data, Sql table definitions, and web based 
documentation, may also be generated. On top of these low level APIs, developers have access to two higher-level set of frameworks; 
Python SalObj\footnote{\url{https://github.com/lsst-ts/ts_salobj}} library and the LabVIEW component template. No higher level framework 
is supported for implementations in Java or C++.

Overall, the system architecture can be divided into three main namespaces; Observatory, Main Telescope (MT) and Auxiliary Telescope 
(AT). The Observatory is the highest level and encapsulates both the Main Telescope, Auxiliary Telescope and global components such
as the script queue, scheduler, environment awareness system, etc (see Fig.~\ref{fig:arc}).

\subsection{SalObj - Python and scripting }\label{sect:salobj}

provides a high level interface 

SalObj is a Python library provides a pythonic and object-oriented interface for SAL components such as CSCs and SAL 
scripts (see Sect.~\ref{sect:scriptq}). The library defines two sets of base classes that are mirror to each other, 
Remote and Controller. A Remote will send commands to and receive telemetry and events from a specific component whereas a 
Controller will receive commands and publish telemetry and events. SalObj also provides BaseCsc, a subclass of Controller 
that handles the standard state transitions and is intended to be used as a parent class for CSC.

Internally, SalObj uses the python library \asyncio\footnote{\url{https://docs.python.org/3/library/asyncio.html}} to handle the 
inherently asynchronous nature of the SAL messaging system.

\subsection{Hardware interface components}\label{sect:hardware_csc}
Probably the most critical or sensitive components of the LSST system architecture are those that directly control hardware. Some 
of these components are going to be delivered directly by external vendors, such as those that will control the main telescope 
mount (MTMount) and the main telescope secondary mirror (MTM2). There are also those that are developed in house, e.g. the 
main telescope M1M3 (MTM1M3).

In some special cases, where fast real time response is required, it is highly desirable that the control software and hardware are part 
of an integrated system. For those systems, the components are developed either using the LabView component template, which is 
part of the LSST infrastructure or in C++ developed using the low level SAL API.

In most other cases, the hardware comes with control software that can be easily interfaced by using standard protocols (such as 
TCP/IP or serial ports), and there is no special need for the component software to reside close to the low level hardware controller. 
In those cases, the components are written in Python using the SalObj library which is also part of the LSST infrastructure. By 
writing these components using a unified language and library (Python+SalObj) we allow a high level of flexibility and 
maintainability of the software and considerably decrease the development cycle.

\subsection{Pure software components}\label{sect:software_csc}
In the LSST System Architecture there are a number of components that, even though they do not control hardware directly, dictate 
what hardware components are supposed to do. Some of these components are responsible for heavy computational routines, 
such as the Optical Feedback Control (MTOFC), which is responsible for applying corrections to both M1M3, M2 and 
hexapod components for the main telescope or even the Scheduler, which is responsible for processing an entire set of 
observatory telemetry information and history of observations to compute an observing queue.

These pure software components are mostly written in Python using SalObj library. There are three special cases of these 
components that form the basis of the LSST System Architecture; the ScriptQueue (Sect.~\ref{sect:scriptq}), Control 
Systems (Sect.~\ref{sect:ocs}) and the Watcher (Sect.~\ref{sect:watcher}). Together, they provide the tools needed for 
integration, commissioning and operation of the observatory.

\subsection{Configuration Management}\label{sect:config}
During commissioning and operations, LSST will have a large number of running software components under the purview of DM, 
Camera, and TSS. In general, the behavior of each of these components is modifiable through configuration information which 
is read in during startup of the component, or possibly changed while the component is running. Careful management of 
this configuration information is crucial to reliable functioning of the Observatory, and to the analysis of its data products.

There are basically two ways configurations are managed, using a configuration database or version management, for 
ascii-file based configuration. Configuration databases can use any type of database technology as long as versioning 
control is properly implemented and verified. 

For file-based configuration, version control is done using git repositories
Git is already a standard in industry as a software management tool and has becoming increasingly used 
to manage general documents and files as well, not to mention that it is already readily available and broadly adopted by the 
project. Therefore, each component must be capable of handling a git-based configuration repository.
These configuration repositories will be hosted on a configuration server at the summit so that, even if communication with the 
base or the internet is not available, components still maintain access to their configuration repositories. 

Several options for configuration file format, and their associated software tools, have been considered. Each of the 
available options naturally has its strengths and weaknesses, and none stand out as being particularly useful for all LSST 
use cases (and/or available for all the project adopted programming languages). The standard adopted for LSST 
software components is YAML (\url{https://yaml.org}). If a specific component is developed in a language without support
to YAML, a waver may be granted.








